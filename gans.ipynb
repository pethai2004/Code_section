{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc1e381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import activations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df6c40cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "(ds_train, ds_test) = tfds.load('mnist', split=['train', 'test'], shuffle_files=True,as_supervised=False)\n",
    "X_data = tf.convert_to_tensor([i['image'] for i in tfds.as_numpy(ds_train)], dtype=tf.float32) / 255\n",
    "X_data_test = tf.convert_to_tensor([i['image'] for i in tfds.as_numpy(ds_test)], dtype=tf.float32) / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1a12b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov2d_block(x, filters=128, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', BN=False, DO=0.):\n",
    "    initializer = keras.initializers.RandomNormal(stddev=0.01)\n",
    "    x = keras.layers.Conv2D(filters, kern, strd, pad, activation=act, use_bias=True, kernel_initializer=initializer)(x)\n",
    "    if BN:\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "    x = act(x)\n",
    "    if DO > 0.:\n",
    "        x = keras.layers.Dropout(D)(x)\n",
    "    return x\n",
    "\n",
    "def mp_conv2d_block(x, filters=128, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', DO=1.):\n",
    "    \n",
    "    initializer = keras.initializers.RandomNormal(stddev=0.01)\n",
    "    x = keras.layers.Conv2D(filters, kern, strd, pad, activation=act, use_bias=True, kernel_initializer=initializer)(x)\n",
    "    x = act(x)\n",
    "    x = keras.layers.Dropout(DO)(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"same\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def deconv2d_block(x, filters=64, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', BN=False, DO=0.):\n",
    "    initializer = RandomNormal(stddev=0.01)\n",
    "    \n",
    "    x = keras.layers.Conv2DTranspose(filters, kern, strd, pad, activation=act, use_bias=True, \n",
    "                                         kernel_initializer=initializer)(x)\n",
    "    if BN:\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "    x = act(x)\n",
    "    if DO > 0.:\n",
    "        x = keras.layers.Dropout(DO)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(x, input_dim=256, return_shape=256):\n",
    "    initializer = RandomNormal(stddev=0.01)\n",
    "    \n",
    "    x = keras.layers.Dense(return_shape, activation='relu',kernel_initializer=initializer, use_bias=True)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d655be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, image_shape=(28, 28, 1)):\n",
    "        self.image_shape = image_shape\n",
    "        self.model_layer = []\n",
    "        self.model = None\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        input_dims = keras.layers.Input(shape=self.image_shape)\n",
    "        xk = mp_conv2d_block(input_dims, filters=128, act=activations.relu, kern=(5, 5), strd=(2, 2), pad='same', DO=1.)\n",
    "        xk = mp_conv2d_block(xk, filters=256, act=activations.relu, kern=(5, 5), strd=(2, 2), pad='same', DO=1.)\n",
    "        xk = mp_conv2d_block(xk, filters=256, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', DO=1.)\n",
    "        xk = keras.layers.Flatten()(xk)\n",
    "        xk = keras.layers.Dense(1)(xk)\n",
    "        \n",
    "        self.model = keras.Model(input_dims, xk)\n",
    "        \n",
    "    def forward_model(self, input_tensor):\n",
    "        return self.model(input_tensor)\n",
    "    \n",
    "    def extent_model(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class Generator:\n",
    "    def __init__(self, latent_z=128, out_latent=128, image_shape=(28, 28, 1)):\n",
    "        self.out_latent = out_latent\n",
    "        self.latent_z = latent_z\n",
    "        self.image_shape = image_shape\n",
    "        self.model_layer = []\n",
    "        self.model = None \n",
    "\n",
    "    def initialize_model(self):\n",
    "        input_dims = keras.layers.Input(shape=self.latent_z)\n",
    "        xk = dense_block(input_dims, input_dim=self.latent_z, return_shape=self.out_latent)\n",
    "        xk = keras.layers.Reshape((1, 1, self.out_latent))(xk)\n",
    "        xk = deconv2d_block(xk, filters=128, act=activations.relu, kern=(4, 4), strd=(1, 1), \n",
    "                                pad='same', BN=False, DO=0.)\n",
    "        xk = deconv2d_block(xk, filters=256, act=activations.relu, kern=(4, 4), strd=(1, 1), \n",
    "                                pad='same', BN=False, DO=0.)\n",
    "        xk = deconv2d_block(xk, filters=256, act=activations.relu, kern=(4, 4), strd=(1, 1), \n",
    "                                pad='same', BN=False, DO=0.)\n",
    "        xk = keras.layers.Flatten()(xk)\n",
    "        xk = keras.layers.Dense(tf.reduce_prod(self.image_shape))(xk)\n",
    "        xk = keras.layers.Reshape(self.image_shape)(xk)\n",
    "        self.model = keras.Model(input_dims, xk)\n",
    "        \n",
    "    def forward_model(self, input_tensor):\n",
    "        return self.model(input_tensor)\n",
    "    \n",
    "    def extent_model(self):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e0b2b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_disc = Discriminator()\n",
    "T_disc.initialize_model()\n",
    "\n",
    "T_gen = Generator()\n",
    "T_gen.initialize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "bdf1c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss_0(D, alpha, p_r, p_g):\n",
    "    interpolate = p_r + alpha * (p_g - p_r)\n",
    "    \n",
    "    with tf.name_scope(\"Gradient_Penalty\"):\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            g_tape.watch(interpolate)\n",
    "            inter_pred_disc = D.forward_model(interpolate)\n",
    "        g_grad = g_tape.gradient(inter_pred_disc, [interpolate])\n",
    "        norm_g = tf.sqrt(tf.reduce_sum(tf.square(g_grad)))\n",
    "        g_grad = tf.reduce_mean(tf.math.squared_difference(norm_g, 1))\n",
    "    \n",
    "    return g_grad\n",
    "        \n",
    "def generator_loss_0(z, G, D, train_sets):\n",
    "    fake_img = G.forward_model(z)\n",
    "    real_score = D.forward_model(fake_img)\n",
    "    fake_score = D.forward_model(train_sets)\n",
    "    gen_loss = - tf.nn.softplus(real_score) \n",
    "    \n",
    "    return gen_loss\n",
    "\n",
    "def discrim_loss_0(z, G, D, train_sets, g_penalty=0.):\n",
    "    fake_img = G.forward_model(z)\n",
    "    real_score = D.forward_model(fake_img)\n",
    "    fake_score = D.forward_model(train_sets)\n",
    "    disc_loss = tf.nn.softplus(fake_score) + tf.nn.softplus(- real_score) \n",
    "    \n",
    "    if g_penalty > 0.:\n",
    "        grad_loss_dc = grad_loss_0(D, alpha=0.5, p_r=train_sets, p_g=fake_img)\n",
    "    disc_loss += grad_loss_dc\n",
    "    return disc_loss, grad_loss_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8b05b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_k = np.random.rand(10, 128)\n",
    "with tf.GradientTape() as gen_tp:\n",
    "    gen_loss = generator_loss_0(z=z_k, G=T_gen, D=T_disc, train_sets=X_data[:10])\n",
    "gen_grad = gen_tp.gradient(gen_loss, T_gen.model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "ea38767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_k = np.random.rand(10, 128)\n",
    "with tf.GradientTape() as disc_tp:\n",
    "    disc_loss, g_ld = discrim_loss_0(z=z_k, G=T_gen, D=T_disc, train_sets=X_data[:10], g_penalty=1.)\n",
    "disc_grad = disc_tp.gradient(disc_loss, T_disc.model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3cd72bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_train(epoch=50):\n",
    "    \n",
    "    for k in range(epoch):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95d579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
