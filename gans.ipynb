{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82aacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import activations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a4c6cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 13:19:15.241907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 13:19:16.964737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46720 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:04:00.0, compute capability: 8.6\n",
      "2022-08-01 13:19:16.969533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 46720 MB memory:  -> device: 1, name: NVIDIA RTX A6000, pci bus id: 0000:0d:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test) = tfds.load('mnist', split=['train', 'test'], shuffle_files=True,as_supervised=False)\n",
    "X_data = tf.convert_to_tensor([i['image'] for i in tfds.as_numpy(ds_train)], dtype=tf.float32) / 255\n",
    "X_data_test = tf.convert_to_tensor([i['image'] for i in tfds.as_numpy(ds_test)], dtype=tf.float32) / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ecaede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_sample(size):\n",
    "    idxs = np.random.choice(X_data.shape[0], size)\n",
    "    return tf.gather(params=X_data, indices=idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ac0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov2d_block(x, filters=128, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', BN=False, DO=0.):\n",
    "    initializer = keras.initializers.RandomNormal(stddev=0.01)\n",
    "    x = keras.layers.Conv2D(filters, kern, strd, pad, activation=act, use_bias=True, kernel_initializer=initializer)(x)\n",
    "    if BN:\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "    x = act(x)\n",
    "    if DO > 0.:\n",
    "        x = keras.layers.Dropout(D)(x)\n",
    "    return x\n",
    "\n",
    "def mp_conv2d_block(x, filters=128, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', DO=1.):\n",
    "    \n",
    "    initializer = keras.initializers.RandomNormal(stddev=0.01)\n",
    "    x = keras.layers.Conv2D(filters, kern, strd, pad, activation=act, use_bias=True, kernel_initializer=initializer)(x)\n",
    "    x = act(x)\n",
    "    x = keras.layers.Dropout(DO)(x)\n",
    "    x = keras.layers.MaxPooling2D(pool_size=(2, 2), strides=None, padding=\"same\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def deconv2d_block(x, filters=64, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', BN=False, DO=0.):\n",
    "    initializer = RandomNormal(stddev=0.01)\n",
    "    \n",
    "    x = keras.layers.Conv2DTranspose(filters, kern, strd, pad, activation=act, use_bias=True, \n",
    "                                         kernel_initializer=initializer)(x)\n",
    "    if BN:\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "    x = act(x)\n",
    "    if DO > 0.:\n",
    "        x = keras.layers.Dropout(DO)(x)\n",
    "    return x\n",
    "\n",
    "def dense_block(x, input_dim=256, return_shape=256):\n",
    "    initializer = RandomNormal(stddev=0.01)\n",
    "    \n",
    "    x = keras.layers.Dense(return_shape, activation='relu',kernel_initializer=initializer, use_bias=True)(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1e35439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator:\n",
    "    def __init__(self, image_shape=(28, 28, 1)):\n",
    "        self.image_shape = image_shape\n",
    "        self.model_layer = []\n",
    "        self.model = None\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        input_dims = keras.layers.Input(shape=self.image_shape)\n",
    "        xk = mp_conv2d_block(input_dims, filters=64, act=activations.relu, kern=(5, 5), strd=(2, 2), pad='same', DO=1.)\n",
    "        xk = mp_conv2d_block(xk, filters=128, act=activations.relu, kern=(5, 5), strd=(2, 2), pad='same', DO=1.)\n",
    "        xk = mp_conv2d_block(xk, filters=128, act=activations.relu, kern=(5, 5), strd=(1, 1), pad='same', DO=1.)\n",
    "        xk = keras.layers.Flatten()(xk)\n",
    "        xk = keras.layers.Dense(1)(xk)\n",
    "        \n",
    "        self.model = keras.Model(input_dims, xk)\n",
    "        \n",
    "    def forward_model(self, input_tensor):\n",
    "        return self.model(input_tensor)\n",
    "    \n",
    "    def extent_model(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "class Generator:\n",
    "    def __init__(self, latent_z=128, out_latent=128, image_shape=(28, 28, 1)):\n",
    "        self.out_latent = out_latent\n",
    "        self.latent_z = latent_z\n",
    "        self.image_shape = image_shape\n",
    "        self.model_layer = []\n",
    "        self.model = None \n",
    "\n",
    "    def initialize_model(self):\n",
    "        input_dims = keras.layers.Input(shape=self.latent_z)\n",
    "        xk = dense_block(input_dims, input_dim=self.latent_z, return_shape=self.out_latent)\n",
    "        xk = keras.layers.Reshape((1, 1, self.out_latent))(xk)\n",
    "        xk = deconv2d_block(xk, filters=64, act=activations.relu, kern=(4, 4), strd=(1, 1), \n",
    "                                pad='same', BN=False, DO=0.)\n",
    "        xk = deconv2d_block(xk, filters=128, act=activations.relu, kern=(4, 4), strd=(1, 1), \n",
    "                                pad='same', BN=False, DO=0.)\n",
    "        xk = deconv2d_block(xk, filters=128, act=activations.relu, kern=(4, 4), strd=(1, 1), \n",
    "                                pad='same', BN=False, DO=0.)\n",
    "        xk = keras.layers.Flatten()(xk)\n",
    "        xk = keras.layers.Dense(tf.reduce_prod(self.image_shape))(xk)\n",
    "        xk = keras.layers.Reshape(self.image_shape)(xk)\n",
    "        self.model = keras.Model(input_dims, xk)\n",
    "        \n",
    "    def forward_model(self, input_tensor):\n",
    "        return self.model(input_tensor)\n",
    "    \n",
    "    def extent_model(self):\n",
    "        raise NotImplementedError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7482f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_loss_0(D, alpha, p_r, p_g):\n",
    "    interpolate = p_r + alpha * (p_g - p_r)\n",
    "    \n",
    "    with tf.name_scope(\"Gradient_Penalty\"):\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            g_tape.watch(interpolate)\n",
    "            inter_pred_disc = D.forward_model(interpolate)\n",
    "        g_grad = g_tape.gradient(inter_pred_disc, [interpolate])\n",
    "        norm_g = tf.sqrt(tf.reduce_sum(tf.square(g_grad)))\n",
    "        g_grad = tf.reduce_mean(tf.math.squared_difference(norm_g, 1))\n",
    "    \n",
    "    return g_grad\n",
    "        \n",
    "def generator_loss_0(z, G, D, train_sets):\n",
    "    fake_img = G.forward_model(z)\n",
    "    real_score = D.forward_model(fake_img)\n",
    "    fake_score = D.forward_model(train_sets)\n",
    "    gen_loss = - tf.nn.softplus(real_score) \n",
    "    \n",
    "    return gen_loss\n",
    "\n",
    "def discrim_loss_0(z, G, D, train_sets, g_penalty=0.):\n",
    "    fake_img = G.forward_model(z)\n",
    "    real_score = D.forward_model(fake_img)\n",
    "    fake_score = D.forward_model(train_sets)\n",
    "    disc_loss = tf.nn.softplus(fake_score) + tf.nn.softplus(- real_score) \n",
    "    \n",
    "    if g_penalty > 0.:\n",
    "        grad_loss_dc = grad_loss_0(D, alpha=0.5, p_r=train_sets, p_g=fake_img)\n",
    "    disc_loss += grad_loss_dc\n",
    "    return disc_loss, grad_loss_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7adf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "latent_dim = 128\n",
    "pm_prior0 = tf.zeros((batch_size, latent_dim))\n",
    "pm_prior1 = tf.ones((batch_size, latent_dim)) * 0.01\n",
    "grad_penalty = 1\n",
    "\n",
    "G_opt = tf.keras.optimizers.RMSprop(0.0001)\n",
    "D_opt = tf.keras.optimizers.RMSprop(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c1941df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def loop_train(D, G, epoch=50):\n",
    "\n",
    "    for e in range(epoch):\n",
    "        prior = tfp.distributions.Normal(pm_prior0, pm_prior1)\n",
    "        z_k = prior.sample()\n",
    "        true_img_k = get_true_sample(size=batch_size)\n",
    "        \n",
    "        with tf.GradientTape() as D_tape:\n",
    "            disc_L, disc_g_loss = discrim_loss_0(z=z_k, G=G, D=D, train_sets=true_img_k, g_penalty=grad_penalty)\n",
    "        disc_G = D_tape.gradient(disc_L, D.model.trainable_variables)\n",
    "        D_opt.apply_gradients(zip(disc_G, D.model.trainable_variables))\n",
    "        \n",
    "        with tf.GradientTape() as G_tape:\n",
    "            gen_L = generator_loss_0(z=z_k, G=G, D=D, train_sets=true_img_k)\n",
    "        gen_G = G_tape.gradient(gen_L, G.model.trainable_variables)\n",
    "        G_opt.apply_gradients(zip(gen_G, G.model.trainable_variables))\n",
    "        \n",
    "        tf.summary.scalar('generator_loss', tf.reduce_mean(gen_L), e)\n",
    "        tf.summary.scalar('discriminator_loss', tf.reduce_mean(disc_L), e)\n",
    "        tf.summary.image('generated_image', G.forward_model(z_k[:3]), e)\n",
    "        tf.print(e, 'generator_loss : ', tf.reduce_mean(gen_L), 'discriminator_loss : ', tf.reduce_mean(disc_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b82206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')] cpu : [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "cpus = tf.config.list_physical_devices('CPU')\n",
    "print(\"gpu :\" , gpus, \"cpu :\", cpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32719f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('GPU:0'):\n",
    "    T_disc = Discriminator()\n",
    "    T_disc.initialize_model()\n",
    "\n",
    "    T_gen = Generator()\n",
    "    T_gen.initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c72696",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 generator_loss :  -0.691327572 discriminator_loss :  1.38715494\n",
      "1 generator_loss :  -0.691343307 discriminator_loss :  1.38655794\n",
      "2 generator_loss :  -0.691363335 discriminator_loss :  1.38693333\n",
      "3 generator_loss :  -0.691264927 discriminator_loss :  1.38684154\n",
      "4 generator_loss :  -0.691398323 discriminator_loss :  1.38587344\n",
      "5 generator_loss :  -0.691491187 discriminator_loss :  1.38444948\n",
      "6 generator_loss :  -0.691111505 discriminator_loss :  1.38320243\n",
      "7 generator_loss :  -0.691399574 discriminator_loss :  1.38226211\n",
      "8 generator_loss :  -0.691490471 discriminator_loss :  1.38006473\n",
      "9 generator_loss :  -0.69155556 discriminator_loss :  1.3785249\n",
      "10 generator_loss :  -0.691622257 discriminator_loss :  1.37707567\n",
      "11 generator_loss :  -0.691723526 discriminator_loss :  1.37541771\n",
      "12 generator_loss :  -0.69176209 discriminator_loss :  1.37329447\n",
      "13 generator_loss :  -0.691911697 discriminator_loss :  1.3710947\n",
      "14 generator_loss :  -0.691735744 discriminator_loss :  1.3693018\n",
      "15 generator_loss :  -0.691903293 discriminator_loss :  1.3672049\n",
      "16 generator_loss :  -0.69205308 discriminator_loss :  1.36466098\n",
      "17 generator_loss :  -0.692098618 discriminator_loss :  1.36269569\n",
      "18 generator_loss :  -0.692141771 discriminator_loss :  1.35994232\n",
      "19 generator_loss :  -0.692359865 discriminator_loss :  1.35709298\n",
      "20 generator_loss :  -0.692237616 discriminator_loss :  1.35405087\n",
      "21 generator_loss :  -0.692481875 discriminator_loss :  1.35082436\n",
      "22 generator_loss :  -0.692436159 discriminator_loss :  1.34822869\n",
      "23 generator_loss :  -0.69268018 discriminator_loss :  1.34520471\n",
      "24 generator_loss :  -0.692406237 discriminator_loss :  1.34295619\n",
      "25 generator_loss :  -0.692661464 discriminator_loss :  1.3394326\n",
      "26 generator_loss :  -0.693001747 discriminator_loss :  1.3365252\n",
      "27 generator_loss :  -0.692079127 discriminator_loss :  1.33433855\n",
      "28 generator_loss :  -0.692599118 discriminator_loss :  1.33180392\n",
      "29 generator_loss :  -0.692721069 discriminator_loss :  1.32950354\n",
      "30 generator_loss :  -0.693195879 discriminator_loss :  1.32767045\n",
      "31 generator_loss :  -0.692581356 discriminator_loss :  1.32473826\n",
      "32 generator_loss :  -0.693085492 discriminator_loss :  1.32189393\n",
      "33 generator_loss :  -0.693181276 discriminator_loss :  1.32038009\n",
      "34 generator_loss :  -0.69346267 discriminator_loss :  1.31685758\n",
      "35 generator_loss :  -0.693333924 discriminator_loss :  1.31519127\n",
      "36 generator_loss :  -0.693787456 discriminator_loss :  1.31198311\n",
      "37 generator_loss :  -0.692876637 discriminator_loss :  1.31048465\n",
      "38 generator_loss :  -0.693427086 discriminator_loss :  1.30771\n",
      "39 generator_loss :  -0.693715215 discriminator_loss :  1.30544174\n",
      "40 generator_loss :  -0.693794906 discriminator_loss :  1.3036921\n",
      "41 generator_loss :  -0.693543136 discriminator_loss :  1.30210745\n",
      "42 generator_loss :  -0.694032133 discriminator_loss :  1.29972422\n",
      "43 generator_loss :  -0.693364382 discriminator_loss :  1.2982893\n",
      "44 generator_loss :  -0.69393903 discriminator_loss :  1.29603398\n",
      "45 generator_loss :  -0.694171131 discriminator_loss :  1.29457426\n",
      "46 generator_loss :  -0.694175541 discriminator_loss :  1.29147172\n",
      "47 generator_loss :  -0.694273412 discriminator_loss :  1.28972232\n",
      "48 generator_loss :  -0.69430393 discriminator_loss :  1.28701961\n",
      "49 generator_loss :  -0.694183588 discriminator_loss :  1.28490329\n",
      "50 generator_loss :  -0.694703937 discriminator_loss :  1.28360593\n",
      "51 generator_loss :  -0.693563461 discriminator_loss :  1.28195727\n",
      "52 generator_loss :  -0.694179118 discriminator_loss :  1.27944624\n",
      "53 generator_loss :  -0.694507122 discriminator_loss :  1.27677536\n",
      "54 generator_loss :  -0.694713891 discriminator_loss :  1.27673614\n",
      "55 generator_loss :  -0.694778562 discriminator_loss :  1.27494884\n",
      "56 generator_loss :  -0.694774806 discriminator_loss :  1.27318728\n",
      "57 generator_loss :  -0.69505775 discriminator_loss :  1.27411234\n",
      "58 generator_loss :  -0.69485867 discriminator_loss :  1.27159822\n",
      "59 generator_loss :  -0.695239604 discriminator_loss :  1.27100337\n",
      "60 generator_loss :  -0.694464803 discriminator_loss :  1.270576\n",
      "61 generator_loss :  -0.69487524 discriminator_loss :  1.27028179\n",
      "62 generator_loss :  -0.695429921 discriminator_loss :  1.26985812\n",
      "63 generator_loss :  -0.694603682 discriminator_loss :  1.26894796\n",
      "64 generator_loss :  -0.695272863 discriminator_loss :  1.26972544\n",
      "65 generator_loss :  -0.695334196 discriminator_loss :  1.26948905\n",
      "66 generator_loss :  -0.695711672 discriminator_loss :  1.26864529\n",
      "67 generator_loss :  -0.694673 discriminator_loss :  1.26846945\n",
      "68 generator_loss :  -0.695350528 discriminator_loss :  1.2673496\n",
      "69 generator_loss :  -0.695508 discriminator_loss :  1.26631474\n",
      "70 generator_loss :  -0.695832312 discriminator_loss :  1.2667625\n",
      "71 generator_loss :  -0.695434213 discriminator_loss :  1.26668382\n",
      "72 generator_loss :  -0.695964575 discriminator_loss :  1.26528013\n",
      "73 generator_loss :  -0.695381522 discriminator_loss :  1.26550126\n",
      "74 generator_loss :  -0.695952415 discriminator_loss :  1.265522\n",
      "75 generator_loss :  -0.695665598 discriminator_loss :  1.26581538\n",
      "76 generator_loss :  -0.696156502 discriminator_loss :  1.26404631\n",
      "77 generator_loss :  -0.695452154 discriminator_loss :  1.26655781\n",
      "78 generator_loss :  -0.69608146 discriminator_loss :  1.26455271\n",
      "79 generator_loss :  -0.696115673 discriminator_loss :  1.26402164\n",
      "80 generator_loss :  -0.696349442 discriminator_loss :  1.26414037\n",
      "81 generator_loss :  -0.695806623 discriminator_loss :  1.26510012\n",
      "82 generator_loss :  -0.696399 discriminator_loss :  1.26371098\n",
      "83 generator_loss :  -0.69612658 discriminator_loss :  1.26498294\n",
      "84 generator_loss :  -0.696644485 discriminator_loss :  1.26267\n",
      "85 generator_loss :  -0.695902705 discriminator_loss :  1.26277471\n",
      "86 generator_loss :  -0.696606278 discriminator_loss :  1.26178646\n",
      "87 generator_loss :  -0.696231723 discriminator_loss :  1.26164818\n",
      "88 generator_loss :  -0.696823239 discriminator_loss :  1.26129508\n",
      "89 generator_loss :  -0.696178198 discriminator_loss :  1.2605772\n",
      "90 generator_loss :  -0.696859956 discriminator_loss :  1.25949252\n",
      "91 generator_loss :  -0.696542561 discriminator_loss :  1.26069021\n",
      "92 generator_loss :  -0.69702512 discriminator_loss :  1.26152372\n",
      "93 generator_loss :  -0.696426272 discriminator_loss :  1.26113713\n",
      "94 generator_loss :  -0.696977913 discriminator_loss :  1.26013672\n",
      "95 generator_loss :  -0.697237372 discriminator_loss :  1.26003718\n",
      "96 generator_loss :  -0.696154594 discriminator_loss :  1.26107764\n",
      "97 generator_loss :  -0.696612418 discriminator_loss :  1.26020145\n",
      "98 generator_loss :  -0.697117388 discriminator_loss :  1.25967348\n",
      "99 generator_loss :  -0.697197616 discriminator_loss :  1.25965214\n",
      "time_execution 196.2023047413677 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "summary = tf.summary.create_file_writer(logdir='test_mnist_gans')\n",
    "with summary.as_default():\n",
    "    with tf.device('GPU:1'):\n",
    "        results = loop_train(D=T_disc, G=T_gen, epoch=100)\n",
    "print('time_execution', time.perf_counter() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb6ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
